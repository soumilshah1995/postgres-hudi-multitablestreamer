
# Ingest Multiple Tables
hoodie.streamer.ingestion.tablesToBeIngested=customers,orders
hoodie.streamer.ingestion.customers.configFile=/Users/soumilshah/IdeaProjects/lakehouse-streamer/universal-datalakehouse-postgres-ingestion-deltastreamer/streamer/configfolder/default_customers_config.properties
hoodie.streamer.ingestion.orders.configFile=/Users/soumilshah/IdeaProjects/lakehouse-streamer/universal-datalakehouse-postgres-ingestion-deltastreamer/streamer/configfolder/default_orders_config.properties


# Common configs
bootstrap.servers=localhost:7092
schema.registry.url=http://localhost:8081
hoodie.streamer.source.kafka.value.deserializer.class=io.confluent.kafka.serializers.KafkaAvroDeserializer

# hive sync
hoodie.datasource.hive_sync.partition_extractor_class=org.apache.hudi.hive.MultiPartKeysValueExtractor
hoodie.datasource.hive_sync.metastore.uris=thrift://localhost:9083
hoodie.datasource.hive_sync.mode=hms
hoodie.datasource.hive_sync.enable=true
hoodie.datasource.write.hive_style_partitioning=true

